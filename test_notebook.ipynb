{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# https://qiita.com/kzkadc/items/e4fc7bc9c003de1eb6d0\n",
    "# argument Parser\n",
    "import argparse\n",
    "\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#import torch.legacy.nn as lnn # do not use?\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import torchvision \n",
    "#from torchvision import datasets, models, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# visdom is visualize the process of learning\n",
    "# torchsummary is network summarizing tool\n",
    "# both are usefull!\n",
    "# https://qiita.com/yasudadesu/items/1dda5f9d1708b6d4d923\n",
    "#\n",
    "import visdom\n",
    "\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vis = visdom.Visdom()\n",
    "#vis.env = 'vae_dcgan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial setting\n",
    "opt = {'dataset':'folder',\n",
    "       'dataroot':'celebA/img_align_celeba/',\n",
    "       'workers':0,\n",
    "       'batchSize':256,\n",
    "       'imageSize':64,\n",
    "       'nz':100,\n",
    "       'ngf':64,\n",
    "       'ndf':64,\n",
    "       'niter':25,\n",
    "       'saveInt':5,\n",
    "       'lr':0.0002,\n",
    "       'beta1':0.5,\n",
    "       'cuda':True,\n",
    "       'ngpu':1,\n",
    "       'netG': '', # if you continue, input the path\n",
    "       'netD': '', # if you continue, input the path\n",
    "       'outf':'./output_model',\n",
    "       'manualSeed':462528}\n",
    "\n",
    "# iptの値の一部をグローバル変数に格納\n",
    "ngpu = int(opt['ngpu']) # GPUの数\n",
    "nz = int(opt['nz']) # 潜在変数のベクトル長 デフォルトは100\n",
    "ngf = int(opt['ngf']) # デフォルトは64\n",
    "ndf = int(opt['ndf']) # デフォルトは64\n",
    "nc = 3 # チャンネル数は3で固定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(opt['outf']) # 引数に渡されたディレクトリに出力imageとモデルのチェックポイントを書き込むディレクトリを作る\n",
    "except OSError:\n",
    "    pass # もしエラーが発生した場合には何もしない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引数にmanualSeedが渡された場合の処理\n",
    "# https://qiita.com/chat-flip/items/4c0b71a7c0f5f6ae437f\n",
    "if opt['manualSeed'] is None:\n",
    "    opt['manualSeed'] = random.randint(1, 10000) # manualSeedがNoneの場合、1~10000の間の一様乱数から整数を取得してseedにする\n",
    "print(\"Random Seed: \", opt['manualSeed']) # 設定されたseedをprint\n",
    "random.seed(opt['manualSeed']) # 乱数のseedにopt.manualSeedを設定\n",
    "torch.manual_seed(opt['manualSeed']) # 畳み込み層の重みの乱数seedを設定\n",
    "if opt['cuda']:\n",
    "    torch.cuda.manual_seed_all(opt['manualSeed']) # GPUを使う場合は別の設定にする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# オートチューナが最適なアルゴリズムを見つける\n",
    "# https://qiita.com/koshian2/items/9877ed4fb3716eac0c37\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPUが利用可能な環境だがopt.cuda引数がtrueでないときにwarningを出す処理\n",
    "if torch.cuda.is_available() and not opt['cuda']:\n",
    "    print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "    \n",
    "# GPUの設定\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "file = glob.glob(opt['dataroot']+'*')\n",
    "print(len(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_list = []\n",
    "\n",
    "# ファイルをオープンする\n",
    "test_data = open('./celebA/list_attr_celeba.txt', \"r\")\n",
    "\n",
    "# 一行ずつ読み込んでは表示する\n",
    "i = 0\n",
    "for line in test_data:\n",
    "    if i == 1:\n",
    "        name = line.split()\n",
    "    if i >= 2:\n",
    "        out = line.split()\n",
    "        attr_list.append(out)\n",
    "    i += 1\n",
    "\n",
    "# ファイルをクローズする\n",
    "test_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref : https://tips-memo.com/pytorch-dataset\n",
    "# define transform\n",
    "transform=transforms.Compose([\n",
    "    transforms.Resize(opt['imageSize']),\n",
    "    transforms.CenterCrop(opt['imageSize']),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "\n",
    "from skimage import io\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "\n",
    "# define dataset\n",
    "# https://qiita.com/sheep96/items/0c2c8216d566f58882aa\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, csv_file_path, root_dir, transform=None):\n",
    "        #csvデータの読み出し\n",
    "        self.image_attr_list = attr_list\n",
    "        self.root_dir = root_dir\n",
    "        #画像データへの処理\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_attr_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #dataframeから画像へのパスとラベルを読み出す\n",
    "        #label = self.image_dataframe.iat[idx, LABEL_IDX]\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.image_attr_list[idx][0])\n",
    "        #画像の読み込み\n",
    "        image = io.imread(img_name)\n",
    "        PIL_image = Image.fromarray(image)\n",
    "        #画像へ処理を加える\n",
    "        if self.transform:\n",
    "            image = self.transform(PIL_image)\n",
    "\n",
    "        return image #, self.image_attr_list[idx][0]\n",
    "    \n",
    "imgDataset = MyDataset(attr_list, opt['dataroot'], transform=transform)\n",
    "\n",
    "#train_data, test_data = train_test_split(imgDataset, test_size=0.2)\n",
    "\n",
    "#print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaderの定義\n",
    "dataloaders = torch.utils.data.DataLoader(imgDataset, batch_size=opt['batchSize'],\n",
    "                                          shuffle=True, num_workers=opt['workers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 読み込んだ画像を表示する\n",
    "\n",
    "# 読み込み関数を定義\n",
    "def imshow(inp, title=None):\n",
    "    inp = inp.numpy().transpose((1,2,0)) # 入力のテンソルをnumpy形式に変換してC*H*Wの並びからH*W*Cの並びに変換する\n",
    "    mean = np.array([0.5, 0.5, 0.5]) # 後で標準化したデータをもとに戻すために使う平均値を格納\n",
    "    std = np.array([0.5, 0.5, 0.5]) # 後で標準化したデータをもとに戻すために使う標準偏差を格納\n",
    "    inp = std * inp + mean # 標準化したデータをもとに戻す\n",
    "    inp = np.clip(inp, 0, 1) # 最小0、最大1の範囲にデータを収める https://note.nkmk.me/python-numpy-clip/\n",
    "    plt.imshow(inp) # matplotlibで画像を表示　http://pynote.hatenablog.com/entry/matplotlib-imshow\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)\n",
    "\n",
    "# dataloaderをイテレータオブジェクトにしてnextの要素を格納する\n",
    "inputs = next(iter(dataloaders)) #https://algorithm.joho.info/programming/python/iter-next-py/\n",
    "\n",
    "# inputs画像を使ってグリッドを生成する\n",
    "out = torchvision.utils.make_grid(inputs) # https://blog.shikoan.com/torchvision-image-tile/\n",
    "print(len(inputs),\n",
    "      inputs.size())\n",
    "\n",
    "imshow(out)\n",
    "#print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 試しに画像を一つ表示してみる\n",
    "imshow(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "# ネットワークの重みを初期化する関数の定義\n",
    "# netGならびにnetDに対して、applyで渡される関数であり、それぞれのネットワークのサブモジュールに対して実施される\n",
    "# https://tutorialmore.com/questions-56844.htm\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__ # 定義されたクラスの元のクラス名を取得する　https://ja.stackoverflow.com/questions/4556/%E3%83%A1%E3%83%B3%E3%83%90%E9%96%A2%E6%95%B0%E3%81%8B%E3%82%89%E3%82%AF%E3%83%A9%E3%82%B9%E3%81%AE%E5%90%8D%E5%89%8D%E3%82%92%E5%8F%96%E5%BE%97%E3%81%99%E3%82%8B%E6%96%B9%E6%B3%95\n",
    "    if classname.find('Conv') != -1: # classnameが含まれる場合の処理（.findで-1が返ってくると指定文字列は含まれていない） https://www.sejuku.net/blog/52207\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 潜在変数にGaussianを仮定し、そこからのサンプリング用のclass\n",
    "# VAEは潜在空間にGaussianを仮定するため\n",
    "# https://qiita.com/kenmatsu4/items/b029d697e9995d93aa24\n",
    "# この部分がReparameterization Trickに該当する\n",
    "# つまり、学習させるのは正規乱数のパラメータの方である\n",
    "class _Sampler(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(_Sampler, self).__init__()\n",
    "        \n",
    "    def forward(self,input):\n",
    "        # inputは2要素のリストであり、index=0が平均値ベクトル、index=1が分散の対数となっている\n",
    "        # Samplerはencoderの出力の結果である2つのベクトルを引数としてとるため、\n",
    "        # 一方を平均ベクトル、もう一方を対数分散ベクトルとなるよう、重みをトレーニングする形となる\n",
    "        mu = input[0]\n",
    "        logvar = input[1] # 分散の対数\n",
    "        \n",
    "        std = logvar.mul(0.5).exp_() #calculate the STDEV\n",
    "        if opt['cuda']:\n",
    "            # epsにstdのサイズと同じサイズのtensorを作る\n",
    "            # tensorの中身にはnormal_()でmean=0,std=1の正規分布に従う乱数を格納する\n",
    "            # https://pytorch.org/docs/stable/tensors.html#torch.Tensor.normal_\n",
    "            eps = torch.cuda.FloatTensor(std.size()).normal_() #random normalized noise\n",
    "        else:\n",
    "            # 上と同様\n",
    "            eps = torch.FloatTensor(std.size()).normal_() #random normalized noise\n",
    "        eps = Variable(eps) # 自動微分を有効にするためVariableクラスでラップする必要があったが、0.4以降は特にいらない？　https://codezine.jp/article/detail/11052\n",
    "        # 戻り値は標準正規分布乱数からmu,stdのパラメータに従う正規分布に戻したもの\n",
    "        return eps.mul(std).add_(mu) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoderの定義\n",
    "class _Encoder(nn.Module):\n",
    "    # 初期化関数\n",
    "    # 引数に画像サイズをとる\n",
    "    def __init__(self,imageSize):\n",
    "        super(_Encoder, self).__init__()\n",
    "        # 2を底とするXの対数を返す\n",
    "        # 2^n = imageSize なので、imageSizeは2のx乗でなければならない\n",
    "        # また、少なくとも3回は畳み込むのでimageSizeが8(2^3)でなければならない\n",
    "        n = math.log2(imageSize)\n",
    "        \n",
    "        # 条件に合致しないときの処理\n",
    "        assert n==round(n),'imageSize must be a power of 2'\n",
    "        assert n>=3,'imageSize must be at least 8'\n",
    "        # nを整数型に変換する\n",
    "        n=int(n)\n",
    "\n",
    "        # pytorchのConv2dについて\n",
    "        # Conv2d(インプットのチャンネル数,アウトプットのチャンネル数,カーネルサイズ)\n",
    "        # https://qiita.com/kazetof/items/6a72926b9f8cd44c218e#43-nnconv2d%E3%81%A8%E3%81%AF\n",
    "        # more detail\n",
    "        # https://pytorch.org/docs/stable/nn.html\n",
    "        # (in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "        \n",
    "        # ここではself.encoderの出力結果をチャネル数nzにして返す畳み込み層を定義している\n",
    "        # forwardで二つのvectorを返している\n",
    "        self.conv1 = nn.Conv2d(ngf * 2**(n-3), nz, 4) # (channel of Input, channel of output, kernel size)\n",
    "        self.conv2 = nn.Conv2d(ngf * 2**(n-3), nz, 4) # (channel of Input, channel of output, kernel size)\n",
    "\n",
    "        # encoderを畳み込み層-バッチノーマライゼーション-LeakyReLUの繰り返しで定義\n",
    "        self.encoder = nn.Sequential()\n",
    "        # input is (nc) x 64 x 64\n",
    "        # https://pytorch.org/docs/stable/nn.html\n",
    "        # (in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "        # 入力チャネル数=3, outputチャネル数=ngf, カーネルサイス=4, ストライド2, パディング=1\n",
    "        # 出力サイズは ((H(W)+2P-Fh(Fn))/2)+1で計算できる\n",
    "        # 入力サイズが64x64の時、出力サイズは32x32になる\n",
    "        # 出力チャネル数はngfで定義（デフォルトで64）\n",
    "        self.encoder.add_module('input-conv',nn.Conv2d(nc, ngf, 4, 2, 1, bias=False))\n",
    "        # 活性化関数にLeakyReLUを使用、x<0のときの傾きを0.2に固定\n",
    "        self.encoder.add_module('input-relu',nn.LeakyReLU(0.2, inplace=True))\n",
    "        # 画像サイズが64x64のとき、64=2^5なのでn=6\n",
    "        # その場合、0～2(6-3=3なので)の繰り返しとなる\n",
    "        for i in range(n-3):\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            # モジュールの名称をpyramid(入力チャネル数)-(出力チャネル数)としている\n",
    "            # 入力チャネル数および出力チャネル数は記載の通り、ngfの2^i倍ずつ増えていく\n",
    "            # カーネルサイズ、ストライド、パディングはずっと同じ、バイアスは使用しない\n",
    "            self.encoder.add_module('pyramid_{0}-{1}_conv'.format(ngf*2**i, ngf * 2**(i+1)), nn.Conv2d(ngf*2**(i), ngf * 2**(i+1), 4, 2, 1, bias=False))\n",
    "            self.encoder.add_module('pyramid_{0}_batchnorm'.format(ngf * 2**(i+1)), nn.BatchNorm2d(ngf * 2**(i+1)))\n",
    "            self.encoder.add_module('pyramid_{0}_relu'.format(ngf * 2**(i+1)), nn.LeakyReLU(0.2, inplace=True))\n",
    "            # モジュールの繰り返しごとに画像サイズが半分になっていく\n",
    "            # 最終的に4x4の画像になるようにnが調整されている\n",
    "            # 最終的なチャネル数は2^(n-3)である。画像サイズ64x64の場合はngf*8となる\n",
    "\n",
    "        # state size. (ngf*8) x 4 x 4\n",
    "\n",
    "    # encoderで入力画像を(ngf*8) x 4 x 4に畳み込み\n",
    "    # その出力をconv1,conv2にかけてnzのサイズの二つのベクトルに変換しreturn\n",
    "    def forward(self,input):\n",
    "        output = self.encoder(input)\n",
    "        return [self.conv1(output),self.conv2(output)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generative Model全体の定義\n",
    "# decoder部分はencoderの逆を行う\n",
    "class _netG(nn.Module):\n",
    "    def __init__(self, imageSize, ngpu):\n",
    "        super(_netG, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        # すでに定義したEncoderとSamplerを定義\n",
    "        self.encoder = _Encoder(imageSize)\n",
    "        self.sampler = _Sampler()\n",
    "        \n",
    "        # encoderと同様に繰り返し回数nはimageSize=2^nとしたときのnとする\n",
    "        # decoderではencoderの逆で倍々にupsamplingしていく\n",
    "        n = math.log2(imageSize)\n",
    "        \n",
    "        # imageSizeが規定に満たないときの処理\n",
    "        assert n==round(n),'imageSize must be a power of 2'\n",
    "        assert n>=3,'imageSize must be at least 8'\n",
    "        # forループを回すためにnを整数型に直す\n",
    "        n=int(n)\n",
    "\n",
    "        # decoderをencoderの逆として定義する\n",
    "        # まず最初にサイズnzのベクトルを入力値に取り、４ｘ４画像に拡大する\n",
    "        self.decoder = nn.Sequential()\n",
    "        # input is Z, going into a convolution\n",
    "        self.decoder.add_module('input-conv', nn.ConvTranspose2d(nz, ngf * 2**(n-3), 4, 1, 0, bias=False))\n",
    "        self.decoder.add_module('input-batchnorm', nn.BatchNorm2d(ngf * 2**(n-3)))\n",
    "        self.decoder.add_module('input-relu', nn.LeakyReLU(0.2, inplace=True))\n",
    "\n",
    "        # state size. (ngf * 2**(n-3)) x 4 x 4\n",
    "\n",
    "        # 入力チャネル数、出力チャネル数はencoderの逆\n",
    "        # forループ内のコードはencoderと同じだが、rangeの定義が異なる\n",
    "        for i in range(n-3, 0, -1):\n",
    "            self.decoder.add_module('pyramid_{0}-{1}_conv'.format(ngf*2**i, ngf * 2**(i-1)),nn.ConvTranspose2d(ngf * 2**i, ngf * 2**(i-1), 4, 2, 1, bias=False))\n",
    "            self.decoder.add_module('pyramid_{0}_batchnorm'.format(ngf * 2**(i-1)), nn.BatchNorm2d(ngf * 2**(i-1)))\n",
    "            self.decoder.add_module('pyramid_{0}_relu'.format(ngf * 2**(i-1)), nn.LeakyReLU(0.2, inplace=True))\n",
    "\n",
    "        # 最終的に元のサイズに戻し、活性化関数tanhを通す\n",
    "        self.decoder.add_module('ouput-conv', nn.ConvTranspose2d(    ngf,      nc, 4, 2, 1, bias=False))\n",
    "        self.decoder.add_module('output-tanh', nn.Tanh())\n",
    "\n",
    "    # 順方向\n",
    "    # endocer-sampler-decoderの順に流して最終結果を得る\n",
    "    def forward(self, input):\n",
    "        # GPUが使える場合\n",
    "        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.encoder, input, range(self.ngpu))\n",
    "            output = nn.parallel.data_parallel(self.sampler, output, range(self.ngpu))\n",
    "            output = nn.parallel.data_parallel(self.decoder, output, range(self.ngpu))\n",
    "        # GPUが使えない場合\n",
    "        else:\n",
    "            output = self.encoder(input)\n",
    "            output = self.sampler(output)\n",
    "            output = self.decoder(output)\n",
    "        return output\n",
    "    # GPUが使える場合に備えてencoder,sampler,decoderをcuda用に変換する関数\n",
    "    # インスタンス化する際に登場する\n",
    "    def make_cuda(self):\n",
    "        self.encoder.cuda()\n",
    "        self.sampler.cuda()\n",
    "        self.decoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成ネットワークの定義\n",
    "netG = _netG(opt['imageSize'],ngpu)\n",
    "# applyはnetG内でselfで定義されたサブモジュールに対して(fn)の関数を適用する\n",
    "# この場合はweights_initなので、重みの初期化を全サブモジュールに対して適用している\n",
    "netG.apply(weights_init)\n",
    "# すでに何らかの学習が行われておりnetGが空でない場合はすでにあるnetGから読み込みを行う\n",
    "if opt['netG'] != '':\n",
    "    netG.load_state_dict(torch.load(opt['netG']))\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminatorモデルの定義\n",
    "class _netD(nn.Module):\n",
    "    def __init__(self, imageSize, ngpu):\n",
    "        super(_netD, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        # こちらも同じようにimageSize=2^nを定義する\n",
    "        n = math.log2(imageSize)\n",
    "        \n",
    "        # 画像サイズが規定外だったときの処理\n",
    "        assert n==round(n),'imageSize must be a power of 2'\n",
    "        assert n>=3,'imageSize must be at least 8'\n",
    "        n=int(n)\n",
    "        \n",
    "        # 以下でモデルの定義を行う\n",
    "        self.main = nn.Sequential()\n",
    "\n",
    "        # input is (nc) x 64 x 64\n",
    "        # ここから画像サイズが半分ずつになっていく\n",
    "        # ndfはDiscriminator用の出力チャネル数\n",
    "        # デフォルトの場合、おおもとの入力チャネル数nc=3、最初の出力チャネル数ndf=64\n",
    "        self.main.add_module('input-conv', nn.Conv2d(nc, ndf, 4, 2, 1, bias=False))\n",
    "        self.main.add_module('relu', nn.LeakyReLU(0.2, inplace=True))\n",
    "\n",
    "        # state size. (ndf) x 32 x 32\n",
    "        # 64x64の場合、n=6なので、0,1,2の繰り返し\n",
    "        # 32x32-16x16-8x8-4x4となり、このループの中では画像サイズが4x4になる\n",
    "        # ngfとなっているところはndfのtypo?\n",
    "        for i in range(n-3):\n",
    "            self.main.add_module('pyramid_{0}-{1}_conv'.format(ngf*2**(i), ngf * 2**(i+1)), nn.Conv2d(ndf * 2 ** (i), ndf * 2 ** (i+1), 4, 2, 1, bias=False))\n",
    "            self.main.add_module('pyramid_{0}_batchnorm'.format(ngf * 2**(i+1)), nn.BatchNorm2d(ndf * 2 ** (i+1)))\n",
    "            self.main.add_module('pyramid_{0}_relu'.format(ngf * 2**(i+1)), nn.LeakyReLU(0.2, inplace=True))\n",
    "\n",
    "        # 最後の層で出力チャネル数1、シグモイド関数にかける\n",
    "        self.main.add_module('output-conv', nn.Conv2d(ndf * 2**(n-3), 1, 4, 1, 0, bias=False))\n",
    "        self.main.add_module('output-sigmoid', nn.Sigmoid())\n",
    "        \n",
    "\n",
    "    # 順方向、書いてあるそのまま\n",
    "    def forward(self, input):\n",
    "        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "\n",
    "        return output.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# netGと同じように定義\n",
    "netD = _netD(opt['imageSize'],ngpu)\n",
    "netD.apply(weights_init)\n",
    "if opt['netD'] != '':\n",
    "    netD.load_state_dict(torch.load(opt.netD))\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 損失関数にはそれぞれBCELoss(Binary Cross Entropy Loss)とMSELoss(Mean Square Error)を使う\n",
    "# https://pytorch.org/docs/stable/nn.html\n",
    "# 必要におうじてもっと詳しく調べること\n",
    "criterion = nn.BCELoss()\n",
    "MSECriterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入力値のサイズを設定\n",
    "input = torch.FloatTensor(opt['batchSize'], 3, opt['imageSize'], opt['imageSize'])\n",
    "# ノイズのサイズを設定、ノイズはバッチサイズx潜在変数ベクトル長x1x1\n",
    "noise = torch.FloatTensor(opt['batchSize'], nz, 1, 1)\n",
    "# 固定ノイズをnoizeと同じサイズとし、標準正規分布からサンプリングする\n",
    "fixed_noise = torch.FloatTensor(opt['batchSize'], nz, 1, 1).normal_(0, 1)\n",
    "# ラベルのサイズを設定、バッチサイズと同じ\n",
    "label = torch.FloatTensor(opt['batchSize'])\n",
    "# 真であれば1、偽であれば0のラベルとする\n",
    "real_label = 1\n",
    "fake_label = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPUが使える場合はすでに設定したモデル、変数をcuda用に変換しておく\n",
    "if opt['cuda']:\n",
    "    netD.cuda()\n",
    "    netG.make_cuda()\n",
    "    criterion.cuda()\n",
    "    MSECriterion.cuda()\n",
    "    input, label = input.cuda(), label.cuda()\n",
    "    noise, fixed_noise = noise.cuda(), fixed_noise.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自動微分用にVariableクラスに変換\n",
    "# 現在は必要ないか？\n",
    "#input = Variable(input)\n",
    "#label = Variable(label)\n",
    "#noise = Variable(noise)\n",
    "#fixed_noise = Variable(fixed_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup optimizer\n",
    "# 最適化法はnetD,netGいずれもAdamとする\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=opt['lr'], betas=(opt['beta1'], 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=opt['lr'], betas=(opt['beta1'], 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_win = None\n",
    "rec_win = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ここから学習部分\n",
    "# 繰り返し回数はoptionで設定、デフォルトは25\n",
    "for epoch in range(opt['niter']):\n",
    "    for i, data in enumerate(dataloaders, 0):\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        # 先にDiscriminatorを訓練する\n",
    "        # data中の画像をreal、ノイズをfakeとしてrealが1になるように訓練していく\n",
    "        \n",
    "        # train with real\n",
    "        # 勾配をゼロに初期化\n",
    "        netD.zero_grad()\n",
    "        # dataから画像をとってくる\n",
    "        real_cpu = data\n",
    "        # 画像数をバッチサイズとする\n",
    "        # バッチサイズはdataloaderで定義されているので、その数分出てくる\n",
    "        batch_size = real_cpu.size(0)\n",
    "        # 画像をリサイズしている？\n",
    "        input.data.resize_(real_cpu.size()).copy_(real_cpu)\n",
    "        # dataからとってきた画像のラベルをすべて1にする\n",
    "        label.data.resize_(real_cpu.size(0)).fill_(real_label)\n",
    "\n",
    "        # 真の画像をnetDを通し、誤差を計算する\n",
    "        # 誤差関数はBinary Cross Entropy\n",
    "        output = netD(input)\n",
    "        #print(\"befor errD_real\",torch.squeeze(output), label)\n",
    "        errD_real = criterion(torch.squeeze(output), label)\n",
    "        # 逆伝播させる\n",
    "        errD_real.backward()\n",
    "        D_x = output.data.mean()\n",
    "\n",
    "        # train with fake\n",
    "        # ノイズデータを使って偽画像を学習させる\n",
    "        # ノイズ画像のおおもとはencoderで出力されるベクトル長と同じ長さのベクトルであり、\n",
    "        # それをdecoderを通して画像にする\n",
    "        noise.data.resize_(batch_size, nz, 1, 1)\n",
    "        noise.data.normal_(0, 1)\n",
    "        # ノイズベクトルをdecoderに通して画像に変換\n",
    "        gen = netG.decoder(noise)\n",
    "        #gen_win = vis.image(gen.data[0].cpu()*0.5+0.5,win = gen_win)\n",
    "        # labelはfakeにする\n",
    "        label.data.fill_(fake_label)\n",
    "        # discriminatorを通して誤差を計算する\n",
    "        # 誤差関数はBCE\n",
    "        output = netD(gen.detach())\n",
    "        #print(\"befor errD_fake\",torch.squeeze(output), label)\n",
    "        errD_fake = criterion(torch.squeeze(output), label)\n",
    "        # 逆伝播させる\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.data.mean()\n",
    "        # discriminatorにおける誤差はrealとfakeの合算とする\n",
    "        errD = errD_real + errD_fake\n",
    "        # 重みを更新\n",
    "        optimizerD.step()\n",
    "        ############################\n",
    "        # (2) Update G network: VAE\n",
    "        ###########################\n",
    "        # VAE部分の学習\n",
    "        \n",
    "        # 勾配の初期化\n",
    "        netG.zero_grad()\n",
    "        \n",
    "        # まずencoderに通して二つのベクトル（平均値ベクトルと対数分散ベクトル）を得る\n",
    "        encoded = netG.encoder(input)\n",
    "        # 得られたベクトルをmu,logvarに入れてreparameterization trickにかける\n",
    "        mu = encoded[0]\n",
    "        logvar = encoded[1]\n",
    "        \n",
    "        # samplerに行く前にKL divergenceを計算する\n",
    "        # なぜKLDを計算して損失関数に加えるのかは以下のサイトを参照\n",
    "        # https://qiita.com/nishiha/items/2264da933504fbe3fc68\n",
    "        KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
    "        KLD = torch.sum(KLD_element).mul_(-0.5)\n",
    "        \n",
    "        # 出力をsamplerに通して結果を得る\n",
    "        sampled = netG.sampler(encoded)\n",
    "        # samplerの出力をdecoderに通して画像を得る\n",
    "        rec = netG.decoder(sampled)\n",
    "        #rec_win = vis.image(rec.data[0].cpu()*0.5+0.5,win = rec_win)\n",
    "        \n",
    "        # 出力画像と入力画像の誤差をMSEで計算\n",
    "        MSEerr = MSECriterion(rec,input)\n",
    "        \n",
    "        # MSEにKLDを加えてVAEの誤差とする\n",
    "        VAEerr = KLD + MSEerr;\n",
    "        # 逆伝播\n",
    "        VAEerr.backward()\n",
    "        # 重みを更新\n",
    "        optimizerG.step()\n",
    "\n",
    "        ############################\n",
    "        # (3) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        # netGと競合させる\n",
    "\n",
    "        label.data.fill_(real_label)  # fake labels are real for generator cost\n",
    "\n",
    "        # 入力画像をnetGに通す\n",
    "        rec = netG(input) # this tensor is freed from mem at this point\n",
    "        # 得られた出力画像をnetDに通す\n",
    "        output = netD(rec)\n",
    "        # 損失関数の計算\n",
    "        #print(\"befor errG_fake\",torch.squeeze(output), label)\n",
    "        errG = criterion(torch.squeeze(output), label)\n",
    "        # 逆伝播\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.data.mean()\n",
    "        # 重みの更新\n",
    "        optimizerG.step()\n",
    "\n",
    "        # 途中経過の出力\n",
    "        print('[%d/%d][%d/%d] Loss_VAE: %.4f Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'\n",
    "              % (epoch, opt['niter'], i, len(dataloaders),\n",
    "                 VAEerr.data, errD.data, errG.data, D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "    # 指定の間隔でモデルの保存\n",
    "    if epoch%opt['saveInt'] == 0 and epoch!=0:\n",
    "        torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (opt['outf'], epoch))\n",
    "        torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (opt['outf'], epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/how-to-debug-causes-of-gpu-memory-leaks/6741/2\n",
    "import gc\n",
    "for obj in gc.get_objects():\n",
    "    try:\n",
    "        if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
    "            print(type(obj), obj.size())\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
